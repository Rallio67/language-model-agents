{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rallio67/language-model-agents/blob/main/softprompt_tpu_tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test out early development model of OpenAssistant\n",
        "This colab notebook allows a person with a colab pro account or access to a TPU to test an early development version of instruction tuning for the open assistant. This code is derived from the KoboldAI client. KoboldAI is not affiliated with OA directly, but we have used their softprompt tuning capabilities for large language models as part of the prototyping of our \n",
        "instruction tuned models. Once the datasets are finished and the full model weight training strategy is executed we will release the full model weights. \n",
        "\n",
        "#Disclaimer\n",
        "This model and (all language models) has the potential to generate undesirable content, especially if prompted to do so. We are working on making our models as helpful and non-toxic as possible, but there is still a lot of work to be done on this front. This is intended for developers on the project to do early evaluations. Use at your own risk.\n",
        "\n",
        "#Learn more about KoboldAI\n",
        "You can check out their project at their github page. They are focused on using language models for interactive storytelling.\n",
        "https://github.com/KoboldAI/KoboldAI-Client\n"
      ],
      "metadata": {
        "id": "6MwWtzT-CIj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install all the needed code and verify your TPU."
      ],
      "metadata": {
        "id": "lznlyK7SB_En"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZmAyFFMouk9"
      },
      "outputs": [],
      "source": [
        "Version = \"https://github.com/ve-forbryderne/KoboldAI-Client\"\n",
        "Provider = \"Cloudflare\"\n",
        "\n",
        "import os\n",
        "\n",
        "#Check for TPU. A TPU is required.\n",
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        "    raise RuntimeError(\"⚠️You can not run this notebook without the TPU accelerator, go to Runtime->Sessions, terminate your session and then try again.⚠️\")\n",
        "print('Now we will need your Google Drive to store settings and saves, you must login with the same account you used for Colab.')\n",
        "\n",
        "#Mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#Load model\n",
        "Model = \"EleutherAI/pythia-13b-deduped\"\n",
        "path = \"\"\n",
        "download = \"\"\n",
        "\n",
        "#Install dependences\n",
        "!wget https://koboldai.org/ckds -O - | bash /dev/stdin $path$download -m $Model -g $Version $tunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The following code block will start the server.\n",
        "Make sure to paste the pythia-13b-instruct-v3-alpha.zip into the folder:\n",
        "/content/KoboldAI-Client/softprompts/pythia13b-instruct-v3-alpha.zip\n",
        "\n",
        "Then click the 'try cloudfare' link to open a browser where you can interact with the softprompt.\n",
        "\n",
        "To use the model with or without the softprompt, click the button in the top right of the user interface called \"Softprompts\" and select the pythia-13b-instruct-v3-alpha.zip file.\n",
        "\n",
        "Type into the text box:\n",
        "User: <your question here>\n",
        "\n",
        "Example:\n",
        "User: why are roses red?\n",
        "\n",
        "Then press entere. Enjoy!"
      ],
      "metadata": {
        "id": "xTJiTPq2E_Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Start the server\n",
        "%cd KoboldAI-Client/\n",
        "!python3 aiserver.py --model EleutherAI/pythia-13b-deduped --colab"
      ],
      "metadata": {
        "id": "vhocACTNBw5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#API Usage Instructions\n",
        "\n",
        "If you would like to use the model as an API, here is some example code. \n",
        "\n",
        "You will need to execute this from another jupyter notebook or colab window while the server is running in the cell above.\n",
        "\n",
        "More information is available on the KoboldAI github."
      ],
      "metadata": {
        "id": "uGbWqzqVF5Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from requests.structures import CaseInsensitiveDict\n",
        "import json\n",
        "\n",
        "#get your link from the above cell\n",
        "link = \"https://straight-dog-ZZZZZZZZZZ-pays.trycloudflare.com\"\n",
        "url = link+\"/api/v1/generate\"\n",
        "headers = CaseInsensitiveDict()\n",
        "headers[\"accept\"] = \"application/json\"\n",
        "headers[\"Content-Type\"] = \"application/json\"\n",
        "\n",
        "#Type the prompt here\n",
        "prompt=\"\"\"I have a question about flowers. Why are roses red?\"\"\"\n",
        "print(prompt)\n",
        "print(\"-\"*50)\n",
        "data = \"\"\"\n",
        "{{\n",
        "  \"prompt\": \"User: {0}\",\n",
        "  \"max_length\":130,\n",
        "  \"singleline\":\"True\"\n",
        "}}\n",
        "\"\"\".format(prompt)\n",
        "\n",
        "resp = requests.post(url, headers=headers, data=data.encode(\"utf-8\"))\n",
        "a = json.loads(resp.content)\n",
        "raw_text=a['results'][0]['text']\n",
        "print(raw_text)\n",
        "print(\"-\"*50)"
      ],
      "metadata": {
        "id": "4sM5-tDtGDKl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}